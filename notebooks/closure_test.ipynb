{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import sys\n",
    "sys.path.append('/home/psimmerl/mds_analysis')\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "from math import ceil, floor\n",
    "\n",
    "from src.histo_utilities import std_color_list as SCL\n",
    "# from src.helper_functions import alert, Table, weight_calc\n",
    "\n",
    "from src import CMS_lumi, tdrstyle\n",
    "root_style = tdrstyle.setTDRStyle()\n",
    "\n",
    "import ROOT as rt\n",
    "from ROOT import RDataFrame\n",
    "from ROOT import TCanvas, TLatex, TLegend, TLine, TBox\n",
    "from ROOT import TH1D, TH2D, TGraph, TGraphErrors, TGraphAsymmErrors\n",
    "\n",
    "# **************************** #\n",
    "LOCAL_DIR = '/home/psimmerl/mds_analysis'\n",
    "OUT_DIR = f'{LOCAL_DIR}/reports/weekly/2024-04-15'\n",
    "\n",
    "# **** #\n",
    "YEAR = ('2022', '2023')[0]\n",
    "MET_CATEGORY = ('lt200', 'low', 'high')[1]\n",
    "TAG_CATEGORY = ('csccsc', 'cscdt')[1]\n",
    "CUTSET = ('l1', 'scs', 'ropt', 'roptDNN', 'ropt_bkgMC_plusBeamHalo', 'tight')[-1]\n",
    "OOT = True#False#\n",
    "\n",
    "SIZE_VAR = TAG_CATEGORY[3:]\n",
    "\n",
    "FN_MC = f'{LOCAL_DIR}/data/processed/mc_{TAG_CATEGORY}_{CUTSET}_{MET_CATEGORY}_{YEAR}_rdf.root'\n",
    "# FN_MC = f'{LOCAL_DIR}/data/processed/mc_{TAG_CATEGORY}{\"OOT\" if OOT else \"\"}_{CUTSET}_{MET_CATEGORY}_rdf.root'\n",
    "FN_R3 = f'{LOCAL_DIR}/data/processed/r3_{TAG_CATEGORY}{\"OOT\" if OOT else \"\"}_{CUTSET}_{MET_CATEGORY}_{YEAR}_rdf.root'\n",
    "\n",
    "# **** #\n",
    "# tight 2022\n",
    "if f\"{TAG_CATEGORY}_{CUTSET}_{MET_CATEGORY}_{YEAR}\" == \"csccsc_tight_low_2022\":\n",
    "    ABCD_DPHI = 2.70\n",
    "    ABCD_SIZE = 140\n",
    "if f\"{TAG_CATEGORY}_{CUTSET}_{MET_CATEGORY}_{YEAR}\" == \"csccsc_tight_high_2022\":\n",
    "    ABCD_DPHI = 1.95 # old\n",
    "    ABCD_SIZE = 100 # old\n",
    "\n",
    "if f\"{TAG_CATEGORY}_{CUTSET}_{MET_CATEGORY}_{YEAR}\" == \"cscdt_tight_low_2022\":\n",
    "    ABCD_DPHI = 2.35 # old\n",
    "    ABCD_SIZE = 129 # old\n",
    "if f\"{TAG_CATEGORY}_{CUTSET}_{MET_CATEGORY}_{YEAR}\" == \"cscdt_tight_high_2022\":\n",
    "    ABCD_DPHI = 2.55 # old\n",
    "    ABCD_SIZE = 113 # old\n",
    "\n",
    "# tight 2023\n",
    "if f\"{TAG_CATEGORY}_{CUTSET}_{MET_CATEGORY}_{YEAR}\" == \"csccsc_tight_low_2023\":\n",
    "    ABCD_DPHI = 2.90 # old\n",
    "    ABCD_SIZE = 146 # old\n",
    "if f\"{TAG_CATEGORY}_{CUTSET}_{MET_CATEGORY}_{YEAR}\" == \"csccsc_tight_high_2023\":\n",
    "    ABCD_DPHI = 2.00 # old\n",
    "    ABCD_SIZE = 96 # old\n",
    "\n",
    "if f\"{TAG_CATEGORY}_{CUTSET}_{MET_CATEGORY}_{YEAR}\" == \"cscdt_tight_low_2023\":\n",
    "    ABCD_DPHI = 2.55 # old\n",
    "    ABCD_SIZE = 123 # old\n",
    "if f\"{TAG_CATEGORY}_{CUTSET}_{MET_CATEGORY}_{YEAR}\" == \"cscdt_tight_high_2023\":\n",
    "    ABCD_DPHI = 1.45 # old\n",
    "    ABCD_SIZE = 119 # old\n",
    "\n",
    "# **** #\n",
    "pathlib.Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# rt.gErrorIgnoreLevel = 1001  # rt.kInfo + 1\n",
    "# rt.gROOT.SetBatch(True)\n",
    "PI = rt.TMath.Pi()\n",
    "\n",
    "# rt.EnableImplicitMT(4)\n",
    "# print('Enabled ROOT\\'s implicit multithreading (sometimes causes a crash)')\n",
    "\n",
    "gc = []\n",
    "\n",
    "# **************** #\n",
    "print(f'{MET_CATEGORY=}')\n",
    "print(f'{TAG_CATEGORY=}')\n",
    "print(f'{CUTSET=}')\n",
    "print(f'{OOT=}')\n",
    "print('')\n",
    "\n",
    "print(f'{ABCD_DPHI=}')\n",
    "print(f'{ABCD_SIZE=}')\n",
    "print('')\n",
    "\n",
    "print(f'{FN_MC=}')\n",
    "print(f'{FN_R3=}')\n",
    "print(f'{OUT_DIR=}')\n",
    "print('')\n",
    "\n",
    "# **************** #\n",
    "rdfs = {\n",
    "    'mc' : RDataFrame('MuonSystem_flat', FN_MC),\n",
    "    'r3' : RDataFrame('MuonSystem_flat', FN_R3),\n",
    "}\n",
    "\n",
    "it_weight = None#33\n",
    "\n",
    "print('Events Read:')\n",
    "for key, rdf in rdfs.items():\n",
    "    if TAG_CATEGORY == 'csccsc':\n",
    "        # rdf = rdf.Filter('tag_dR > 1.5')\n",
    "        rdf = rdf.Alias('tag_size', 'csc1Size')\n",
    "        rdf = rdf.Alias('tag_ctau', 'csc1CTau')\n",
    "\n",
    "    if TAG_CATEGORY == 'cscdt':\n",
    "        # rdf = rdf.Filter('tag_dPhi > 0.4')\n",
    "        rdf = rdf.Alias('tag_size', 'dtSize')\n",
    "        rdf = rdf.Alias('tag_ctau', 'dtCTau')\n",
    "\n",
    "    if 'r3' in key and it_weight is not None:\n",
    "        weight = rdf.Sum('weight').GetValue()\n",
    "        print(f'old weight = {weight:,.2f}')\n",
    "        rdf = rdf.Redefine('weight', f'weight * {it_weight/weight}')\n",
    "\n",
    "    count, weight = rdf.Count().GetValue(), rdf.Sum('weight').GetValue()\n",
    "    print(f'  {key} = {count:,} ({weight:,.2f})')\n",
    "\n",
    "    rdfs[key] = rdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'OOT' not in FN_R3:\n",
    "    raise Warning('data is not OOT!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = TCanvas('','',2*800,800)\n",
    "canvas.Divide(2,1)\n",
    "canvas.SetGrid()\n",
    "\n",
    "hinfos = { \n",
    "    'tag_dPhi' : {\n",
    "        'form' : (f';|#Delta#phi|;fraction of events',32,0,np.pi),\n",
    "        'form' : (f';|#Delta#phi|;fraction of events',16,0,np.pi),\n",
    "        'form' : (f';|#Delta#phi|;fraction of events',8,0,np.pi),\n",
    "    },\n",
    "   f'{SIZE_VAR}{\"1\" if SIZE_VAR == \"csc\" else \"\"}Size' : {\n",
    "        'form' : (f';{SIZE_VAR}{\"1\" if SIZE_VAR == \"csc\" else \"\"}Size;fraction of events',25,50,200),\n",
    "        # 'form' : (f';{SIZE_VAR}{\"1\" if SIZE_VAR == \"csc\" else \"\"}Size;fraction of events',25,65,100),\n",
    "        # 'form' : (f';{SIZE_VAR}{\"1\" if SIZE_VAR == \"csc\" else \"\"}Size;fraction of events',15,50,80),\n",
    "        # 'form' : (f';{SIZE_VAR}{\"1\" if SIZE_VAR == \"csc\" else \"\"}Size;fraction of events',10,50,80),\n",
    "        # 'form' : (f';{SIZE_VAR}{\"1\" if SIZE_VAR == \"csc\" else \"\"}Size;fraction of events',25,50,500),\n",
    "    },\n",
    "    # 'csc0Phi' : {\n",
    "    #     'form' : (f';#phi_{{var}};fraction of events',32,0,np.pi),\n",
    "    # },\n",
    "}\n",
    "\n",
    "for ixv, (xv, hinfo) in enumerate(hinfos.items()):\n",
    "    canvas.cd(ixv+1)\n",
    "    # canvas.cd(ixv+1).SetLogy()\n",
    "    form = hinfo['form']\n",
    "\n",
    "    # **** #\n",
    "    legend = TLegend(0.67, 0.72, 0.94, 0.94)\n",
    "    legend.SetBorderSize(0)\n",
    "    legend.SetFillColorAlpha(rt.kBlack, 0.0)#0.2)\n",
    "    legend.SetTextSize(0.04)\n",
    "    legend.SetMargin(0.15)\n",
    "\n",
    "\n",
    "    # **** #\n",
    "\n",
    "    h1 = rdfs['mc'].Histo1D(('Signal',*form),xv,).GetValue()\n",
    "    h2 = rdfs['r3'].Histo1D(('Data'+(', OOT' if OOT else ''),*form),xv,).GetValue()\n",
    "\n",
    "    hhs = [h1,h2]\n",
    "    # hmax = max([h.GetMaximum() for h in hhs])\n",
    "    hmax = max([h.GetMaximum() / h.Integral() if h.Integral() else 0 for h in hhs])\n",
    "    for ih, hh in enumerate(hhs):\n",
    "        nev = hh.Integral()\n",
    "        if hmax < 1 and nev:\n",
    "            hh.Scale(1/hh.Integral())\n",
    "        hh.SetMinimum(0)\n",
    "        hh.SetMaximum(hmax*1.1)\n",
    "        hh.SetLineColor(SCL[ih])\n",
    "        hh.SetLineWidth(3)\n",
    "        hh.Draw('histe same')\n",
    "        legend.AddEntry(hh, hh.GetName(), 'L')\n",
    "\n",
    "\n",
    "    legend.Draw()\n",
    "    gc.extend([legend]+hhs)\n",
    "canvas.Draw()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABCD Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.optimize import minimize, basinhopping\n",
    "# from scipy.stats import poisson, expon#, gamma\n",
    "# from scipy.special import gamma, loggamma\n",
    "\n",
    "\n",
    "# wt_mc = rdfs['mc'].AsNumpy(['weight','tag_dPhi','tag_size'])\n",
    "# wt_mc, dp_mc, sz_mc = wt_mc['weight'], wt_mc['tag_dPhi'], wt_mc['tag_size']\n",
    "\n",
    "# wt_r3 = rdfs['r3'].AsNumpy(['weight','tag_dPhi','tag_size'])\n",
    "# wt_r3, dp_r3, sz_r3 = wt_r3['weight'], wt_r3['tag_dPhi'], wt_r3['tag_size']\n",
    "# wt_r3 = 73/np.sum(wt_r3)*wt_r3\n",
    "\n",
    "# rng = np.random.default_rng()#seed=0)\n",
    "\n",
    "# def abcd_likelihood(pars, sig, obs):\n",
    "#     def pois(o, n, log=True):\n",
    "#         if log:\n",
    "#             return o*np.log(n) - n# - loggamma(o+1)\n",
    "#         return n**o * np.exp(-1*n) / gamma(o+1)\n",
    "#     c1, c2, bkgc, mu = pars\n",
    "#     # bkgb, bkgc, bkgd, mu = pars\n",
    "#     sig_a, sig_b, sig_c, sig_d = sig\n",
    "#     obs_a, obs_b, obs_c, obs_d = obs\n",
    "\n",
    "#     # bkga = bkgb*bkgd/bkgc\n",
    "#     # bkgbe = bkga * (1/bkgb + 1/bkgc + 1/bkgd)**0/5\n",
    "\n",
    "#     N_a = c1*c2*bkgc + mu*sig_a # bkga + mu*sig_a # \n",
    "#     N_b = c1*bkgc + mu*sig_b # bkgb + mu*sig_b # \n",
    "#     N_c = bkgc + mu*sig_c # bkgc + mu*sig_c # \n",
    "#     N_d = c2*bkgc + mu*sig_d # bkgd + mu*sig_d # \n",
    "#     # print(N_a, obs_a, poisson.pmf(obs_a, round(N_a)))\n",
    "#     # print(N_b, obs_b, poisson.pmf(obs_b, round(N_b)))\n",
    "#     # print(N_c, obs_c, poisson.pmf(obs_c, round(N_c)))\n",
    "#     # print(N_d, obs_d, poisson.pmf(obs_d, round(N_d)))\n",
    "#     # print('')\n",
    "#     p = lambda o, n: poisson.logpmf(np.round(o), n) # pois(o, n)#\n",
    "#     return -( p(obs_a, N_a) + p(obs_b, N_b) + p(obs_c, N_c) + p(obs_d, N_d) )\n",
    "#     # return -100 * ( p(obs_a, N_a) * p(obs_b, N_b) * p(obs_c, N_c) * p(obs_d, N_d) )**(1/4)\n",
    "\n",
    "# dp_szs = [[round(dp,2),int(sz)] for dp in np.arange(1.0, 3.15+0.05, 0.05) for sz in np.arange(60,150+1,1)]\n",
    "\n",
    "# bounds, results = [], []\n",
    "# best_bounds, best_res, best_mu = None, None, np.inf\n",
    "# for iter in range(len(dp_szs)):#range(1000):\n",
    "#     if len(dp_szs) == 0:\n",
    "#         break\n",
    "#     # dp, sz = 2.75, 81\n",
    "#     # while [dp, sz] in bounds:\n",
    "#     #     dp = round(rng.uniform(0.4, np.pi),2)\n",
    "#     #     sz = round(rng.uniform(50, 150))\n",
    "#     dp, sz = rng.choice(dp_szs)\n",
    "#     dp_szs.remove([dp,sz])\n",
    "\n",
    "#     a_mc = np.sum(wt_mc[(dp_mc >= dp) & (sz_mc >= sz)])\n",
    "#     b_mc = np.sum(wt_mc[(dp_mc >= dp) & (sz_mc < sz)])\n",
    "#     c_mc = np.sum(wt_mc[(dp_mc < dp) & (sz_mc < sz)])\n",
    "#     d_mc = np.sum(wt_mc[(dp_mc < dp) & (sz_mc >= sz)])\n",
    "\n",
    "#     a_r3 = np.sum(wt_r3[(dp_r3 >= dp) & (sz_r3 >= sz)])\n",
    "#     b_r3 = np.sum(wt_r3[(dp_r3 >= dp) & (sz_r3 < sz)])\n",
    "#     c_r3 = np.sum(wt_r3[(dp_r3 < dp) & (sz_r3 < sz)])\n",
    "#     d_r3 = np.sum(wt_r3[(dp_r3 < dp) & (sz_r3 >= sz)])\n",
    "\n",
    "#     # a_r3 = rdfs['r3'].Filter(f'(tag_dPhi >= {dp}) && (tag_size >= {sz})').Sum('weight')\n",
    "#     # b_r3 = rdfs['r3'].Filter(f'(tag_dPhi >= {dp}) && (tag_size < {sz})').Sum('weight')\n",
    "#     # c_r3 = rdfs['r3'].Filter(f'(tag_dPhi < {dp}) && (tag_size < {sz})').Sum('weight')\n",
    "#     # d_r3 = rdfs['r3'].Filter(f'(tag_dPhi < {dp}) && (tag_size >= {sz})').Sum('weight')\n",
    "#     # a_r3, b_r3, c_r3, d_r3 = a_r3.GetValue(), b_r3.GetValue(), c_r3.GetValue(), d_r3.GetValue()\n",
    "\n",
    "#     if b_r3 == 0 or c_r3 == 0 or d_r3 == 0:# or b_mc == 0 or c_mc == 0 or d_mc == 0:\n",
    "#         bounds.append([dp, sz])\n",
    "#         results.append(None)\n",
    "#         continue\n",
    "\n",
    "#     # a_mc = rdfs['mc'].Filter(f'(tag_dPhi >= {dp}) && (tag_size >= {sz})').Sum('weight')\n",
    "#     # b_mc = rdfs['mc'].Filter(f'(tag_dPhi >= {dp}) && (tag_size < {sz})').Sum('weight')\n",
    "#     # c_mc = rdfs['mc'].Filter(f'(tag_dPhi < {dp}) && (tag_size < {sz})').Sum('weight')\n",
    "#     # d_mc = rdfs['mc'].Filter(f'(tag_dPhi < {dp}) && (tag_size >= {sz})').Sum('weight')\n",
    "#     # a_mc, b_mc, c_mc, d_mc = a_mc.GetValue(), b_mc.GetValue(), c_mc.GetValue(), d_mc.GetValue()\n",
    "\n",
    "#     ap_r3 = b_r3*d_r3/c_r3\n",
    "#     ape_r3 = ap_r3*(1/b_r3 + 1/c_r3 + 1/d_r3)**0.5\n",
    "#     # if abs(a_r3-ap_r3)/((a_r3**0.5 + ape_r3)**0.5) > 1:\n",
    "#     #     bounds.append([dp, sz])\n",
    "#     #     results.append(None)\n",
    "#     #     continue\n",
    "#     a_r3 = ap_r3\n",
    "\n",
    "#     c1, c2, bkgc = b_r3/c_r3, d_r3/c_r3, c_r3\n",
    "#     mu = ((3/2 + ap_r3**0.5)**2 - ap_r3)/a_mc\n",
    "#     # mu = min(mu,1)\n",
    "#     cl_constraint = {\n",
    "#         'type': 'eq',\n",
    "#         # 'fun' : lambda x: 3 - x[3]*a_mc / ( (x[0]*x[2]/x[1])**0.5 ),\n",
    "#         # 'fun' : lambda x: 3 - x[3]*a_mc / ( x[0]*x[2]/x[1]*(1/x[0]+1/x[1]+1/x[2])**0.5 ),\n",
    "#         # 'fun' : lambda x: 3 - 2*( (a_r3)**0.5 - (x[0]*x[1]*x[2])**0.5 )\n",
    "#         'fun' : lambda x: 3 - 2*( (x[0]*x[1]*x[2] + x[3]*a_mc)**0.5 - (x[0]*x[1]*x[2])**0.5 ),\n",
    "#         # 'fun' : lambda x: 3 - 2*( (a_r3 + x[3]*a_mc)**0.5 - (a_r3)**0.5 ),\n",
    "#         # 'fun' : lambda x: 3 - x[3]*a_mc / (x[0]*x[1]*x[2])**0.5,\n",
    "#         # 'fun' : lambda x: 3 - x[3]*a_mc / (a_r3)**0.5,\n",
    "#         # 'fun' : lambda x: 3 - 2*( (a_r3)**0.5 - (x[0]*x[2]/x[1])**0.5 )\n",
    "#         # 'fun' : lambda x: 3 - 2*( (x[0]*x[2]/x[1] + x[3]*a_mc)**0.5 - (x[0]*x[2]/x[1])**0.5 )\n",
    "#         # 'fun' : lambda x: 3 - 2*( (x[0]*x[2]/x[1] + x[3]*a_mc)**0.5 - x[0]*x[2]/x[1]*(1/x[0]+1/x[1]+1/x[2])**0.5 )\n",
    "#         # 'fun' : lambda x: 3 - 2*( ((x[0]*x[2]/x[1]*(1/x[0]+1/x[1]+1/x[2])**0.5)**2 + x[3]*a_mc)**0.5 - x[0]*x[2]/x[1]*(1/x[0]+1/x[1]+1/x[2])**0.5 )\n",
    "#         # 'fun' : lambda x: 3 - 2*( (a_r3)**0.5 - x[0]*x[2]/x[1]*(1/x[0]+1/x[1]+1/x[2])**0.5 )\n",
    "#         # 'fun' : lambda x: 3 - 2*( ape_r3 - x[0]*x[2]/x[1]*(1/x[0]+1/x[1]+1/x[2])**0.5 )\n",
    "#     }\n",
    "\n",
    "#     res = minimize(\n",
    "#     # res = basinhopping(\n",
    "#         abcd_likelihood,\n",
    "#         x0=(c1, c2, bkgc, 1),#mu),#(b_r3, c_r3, d_r3, mu),#\n",
    "#         args=((a_mc, b_mc, c_mc, d_mc), (a_r3, b_r3, c_r3, d_r3)),\n",
    "#         # method='SLSQP',#'trust-constr',#'Nelder-Mead',\n",
    "#         bounds=(\n",
    "#             (c1/100, c1*100),#(1e-9, 7*b_r3),#\n",
    "#             (c2/100, c2*100),#(1e-9, 7*c_r3),#\n",
    "#             (bkgc/10, bkgc*10),#(1e-9, 7*d_r3),#\n",
    "#             (0, None),\n",
    "#         ),\n",
    "#         constraints=cl_constraint,\n",
    "#         options={'maxiter' : 1000},\n",
    "#         # minimizer_kwargs={\n",
    "#         #     'args':  ((a_mc, b_mc, c_mc, d_mc), (a_r3, b_r3, c_r3, d_r3)),\n",
    "#         #     'bounds' : (\n",
    "#         #         (0, 3*b_r3),#c1),\n",
    "#         #         (1, 3*c_r3),#c2),\n",
    "#         #         (0, 3*d_r3),#bkgc),\n",
    "#         #         (0, 1),\n",
    "#         #     ),\n",
    "#         #     'constraints' : cl_constraint,\n",
    "#         # },\n",
    "#         # niter=20,\n",
    "#     )\n",
    "#     bounds.append([dp, sz])\n",
    "#     results.append(res)\n",
    "#     if res.success and res.x[-1] < best_mu and res.x[-1] > 0:\n",
    "#         best_bounds = (dp, sz)\n",
    "#         best_res = res\n",
    "#         best_mu = res.x[-1]\n",
    "#         c1, c2, bkgc, mu = res.x\n",
    "#         # bkgb, bkgc, bkgd, mu = res.x\n",
    "#         bkgb, bkgd = c1*bkgc, c2*bkgc\n",
    "#         bkga, bkgae = bkgb*bkgd/bkgc, bkgb*bkgd/bkgc*(1/bkgb + 1/bkgc + 1/bkgd)**0.5\n",
    "#         s12_sbb = 2*((bkga + mu*a_mc)**0.5 - bkga**0.5)\n",
    "#         s12_r3b = 2*((a_r3)**0.5 - bkga**0.5)\n",
    "#         print(f'n iters, neg log-likelihood = {res.nit:>4.0f}, {res.fun:>6.3f}')\n",
    "#         # print(f'dphi, size = {dp:>4.2f}, {sz:>3.0f}')\n",
    "#         # print(f'c1, c2, mu = {c1:>5.3f}, {c2:>5.3f}, {mu:.3e}')\n",
    "#         print(f'dphi, size, mu = {dp:>4.2f}, {sz:>3.0f}, {mu:.3e}')\n",
    "#         print(f'MC  : a, b, c, d = {mu*a_mc:6.2f}, {mu*b_mc:6.2f}, {mu*c_mc:6.2f}, {mu*d_mc:6.2f}')\n",
    "#         # print(f'Bkg : a, b, c, d = {c1*c2*bkgc:>6.2f}, {c1*bkgc:>6.2f}, {bkgc:>6.2f}, {c2*bkgc:>6.2f}')\n",
    "#         print(f'Bkg : a, b, c, d = {bkga:>6.2f}, {bkgb:>6.2f}, {bkgc:>6.2f}, {bkgd:>6.2f}')\n",
    "#         print(f'R3  : a, b, c, d = {a_r3:>6.2f}, {b_r3:>6.2f}, {c_r3:>6.2f}, {d_r3:>6.2f}')\n",
    "#         # print(f'2S_12(s+b,b) = {2*((c1*c2*bkgc + mu*a_mc)**0.5 - (c1*c2*bkgc)**0.5):.2f}')\n",
    "#         # print(f'2S_12( r3,b) = {2*((a_r3)**0.5 - (c1*c2*bkgc)**0.5):.2f}')\n",
    "#         print(f'2S_12(s+b,b), 2S_12(r3,b) = {s12_sbb:>3.2f}, {s12_r3b:>3.2f}')\n",
    "#         print(f'S_1(s,b), S_1(s,be) = {mu*a_mc / bkga**0.5:.2f}, {mu*a_mc / bkgae:.2f}')\n",
    "#         print('')\n",
    "\n",
    "# # res = best_res\n",
    "# # c1, c2, bkgc, mu = res.x\n",
    "# # bkgb, bkgc, bkgd, mu = res.x\n",
    "# # dp, sz = best_bounds\n",
    "# # print(f'dphi={dp:.2f}, size={sz:.0f}')\n",
    "# # print(f'nit={res.nit:.0f}, mu={mu:.2e}, bkgc={bkgc:.1f}, c1={c1:.2f}, c2={c2:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sizes = np.linspace(50,150,101) #if ABCD_SIZE is None else np.array([ABCD_SIZE])\n",
    "# dphis = np.linspace(0.4,np.pi,50) #if ABCD_DPHI is None else np.array([ABCD_DPHI])\n",
    "''' CSC-DT\n",
    "s2b   = 944.8692401312594\n",
    "dphi  = 2.302329596368428\n",
    "size  = 72.0\n",
    "a_mc  = 668.1234470313939\n",
    "ap_r3 = 0.5\n",
    "'''\n",
    "\n",
    "min_dphi = min([rdf.Min('tag_dPhi').GetValue() for k, rdf in rdfs.items()])\n",
    "max_dphi = max([rdf.Max('tag_dPhi').GetValue() for k, rdf in rdfs.items()])\n",
    "min_size = min([rdf.Min('tag_size').GetValue() for k, rdf in rdfs.items()])\n",
    "max_size = max([rdf.Max('tag_size').GetValue() for k, rdf in rdfs.items()])\n",
    "# if TAG_CATEGORY == 'csc' and MET_CATEGORY == 'low':\n",
    "#     min_dphi = 1\n",
    "# elif TAG_CATEGORY == 'csc' and MET_CATEGORY == 'high':\n",
    "#     min_dphi = 0\n",
    "# elif TAG_CATEGORY == 'dt' and MET_CATEGORY == 'low':\n",
    "#     min_dphi = 0.4\n",
    "# elif TAG_CATEGORY == 'dt' and MET_CATEGORY == 'high':\n",
    "#     min_dphi = 0.4\n",
    "\n",
    "\n",
    "# sizes = np.linspace(50,150,101)\n",
    "# dphis = np.linspace(2/3*np.pi,np.pi,50)\n",
    "# dphis = np.linspace(min_dphi,np.pi,50)\n",
    "\n",
    "# sizes = np.arange(100,150+1,1)\n",
    "# dphis = np.arange(0.40,3.15+0.05,0.05)\n",
    "# sizes = np.arange(max(50,min_size),min(150,max_size)+1,1)\n",
    "sizes = np.arange(max(50,(min_size//2)*2),min(150,max_size)+2,2)\n",
    "dphis = np.arange(max(1.00,(min_dphi//0.05)*0.05),min(3.15,(max_dphi//0.05)*0.05)+0.05,0.05)\n",
    "\n",
    "# sizes = np.arange(max(50,min_size)+1,min(150,max_size),1)\n",
    "# dphis = np.arange(max(1.00,(min_dphi//0.05)*0.05)+0.05,min(3.15,(max_dphi//0.05)*0.05),0.05)\n",
    "''' CSC-DT\n",
    "s2b   = 955.1209859554683\n",
    "dphi  = 2.2653661311599866\n",
    "size  = 72.0\n",
    "a_mc  = 675.3725260226929\n",
    "ap_r3 = 0.5\n",
    "'''\n",
    "\n",
    "wt_mc = rdfs['mc'].AsNumpy(['weight','tag_dPhi','tag_size'])\n",
    "wt_mc, dp_mc, sz_mc = wt_mc['weight'], wt_mc['tag_dPhi'], wt_mc['tag_size']\n",
    "\n",
    "wt_r3 = rdfs['r3'].AsNumpy(['weight','tag_dPhi','tag_size'])\n",
    "wt_r3, dp_r3, sz_r3 = wt_r3['weight'], wt_r3['tag_dPhi'], wt_r3['tag_size']\n",
    "\n",
    "if 'high' in FN_MC: # TODO: Replace this with a pure numpy version, it will be much faster\n",
    "    # a_mc_scan = [ [rdfs['mc'].Filter(f'(tag_dPhi < {dp}) && (tag_size >= {sz})').Sum('weight') for sz in sizes] for dp in dphis ]\n",
    "    # b_mc_scan = [ [rdfs['mc'].Filter(f'(tag_dPhi < {dp}) && (tag_size < {sz})').Sum('weight') for sz in sizes] for dp in dphis ]\n",
    "    # c_mc_scan = [ [rdfs['mc'].Filter(f'(tag_dPhi >= {dp}) && (tag_size < {sz})').Sum('weight') for sz in sizes] for dp in dphis ]\n",
    "    # d_mc_scan = [ [rdfs['mc'].Filter(f'(tag_dPhi >= {dp}) && (tag_size >= {sz})').Sum('weight') for sz in sizes] for dp in dphis ]\n",
    "\n",
    "    # a_r3_scan = [ [rdfs['r3'].Filter(f'(tag_dPhi < {dp}) && (tag_size >= {sz})').Sum('weight') for sz in sizes] for dp in dphis ]\n",
    "    # b_r3_scan = [ [rdfs['r3'].Filter(f'(tag_dPhi < {dp}) && (tag_size < {sz})').Sum('weight') for sz in sizes] for dp in dphis ]\n",
    "    # c_r3_scan = [ [rdfs['r3'].Filter(f'(tag_dPhi >= {dp}) && (tag_size < {sz})').Sum('weight') for sz in sizes] for dp in dphis ]\n",
    "    # d_r3_scan = [ [rdfs['r3'].Filter(f'(tag_dPhi >= {dp}) && (tag_size >= {sz})').Sum('weight') for sz in sizes] for dp in dphis ]\n",
    "    a_mc_scan = np.array([ [np.sum(wt_mc[(dp_mc < dp) & (sz_mc >= sz)]) for sz in sizes] for dp in dphis ], dtype=float)\n",
    "    b_mc_scan = np.array([ [np.sum(wt_mc[(dp_mc < dp) & (sz_mc < sz)]) for sz in sizes] for dp in dphis ], dtype=float)\n",
    "    c_mc_scan = np.array([ [np.sum(wt_mc[(dp_mc >= dp) & (sz_mc < sz)]) for sz in sizes] for dp in dphis ], dtype=float)\n",
    "    d_mc_scan = np.array([ [np.sum(wt_mc[(dp_mc >= dp) & (sz_mc >= sz)]) for sz in sizes] for dp in dphis ], dtype=float)\n",
    "\n",
    "    a_r3_scan = np.array([ [np.sum(wt_r3[(dp_r3 < dp) & (sz_r3 >= sz)]) for sz in sizes] for dp in dphis ], dtype=float)\n",
    "    b_r3_scan = np.array([ [np.sum(wt_r3[(dp_r3 < dp) & (sz_r3 < sz)]) for sz in sizes] for dp in dphis ], dtype=float)\n",
    "    c_r3_scan = np.array([ [np.sum(wt_r3[(dp_r3 >= dp) & (sz_r3 < sz)]) for sz in sizes] for dp in dphis ], dtype=float)\n",
    "    d_r3_scan = np.array([ [np.sum(wt_r3[(dp_r3 >= dp) & (sz_r3 >= sz)]) for sz in sizes] for dp in dphis ], dtype=float)\n",
    "else:\n",
    "    # a_mc_scan = [ [rdfs['mc'].Filter(f'(tag_dPhi >= {dp}) && (tag_size >= {sz})').Sum('weight') for sz in sizes] for dp in dphis ]\n",
    "    # b_mc_scan = [ [rdfs['mc'].Filter(f'(tag_dPhi >= {dp}) && (tag_size < {sz})').Sum('weight') for sz in sizes] for dp in dphis ]\n",
    "    # c_mc_scan = [ [rdfs['mc'].Filter(f'(tag_dPhi < {dp}) && (tag_size < {sz})').Sum('weight') for sz in sizes] for dp in dphis ]\n",
    "    # d_mc_scan = [ [rdfs['mc'].Filter(f'(tag_dPhi < {dp}) && (tag_size >= {sz})').Sum('weight') for sz in sizes] for dp in dphis ]\n",
    "\n",
    "    # a_r3_scan = [ [rdfs['r3'].Filter(f'(tag_dPhi >= {dp}) && (tag_size >= {sz})').Sum('weight') for sz in sizes] for dp in dphis ]\n",
    "    # b_r3_scan = [ [rdfs['r3'].Filter(f'(tag_dPhi >= {dp}) && (tag_size < {sz})').Sum('weight') for sz in sizes] for dp in dphis ]\n",
    "    # c_r3_scan = [ [rdfs['r3'].Filter(f'(tag_dPhi < {dp}) && (tag_size < {sz})').Sum('weight') for sz in sizes] for dp in dphis ]\n",
    "    # d_r3_scan = [ [rdfs['r3'].Filter(f'(tag_dPhi < {dp}) && (tag_size >= {sz})').Sum('weight') for sz in sizes] for dp in dphis ]\n",
    "    a_mc_scan = np.array([ [np.sum(wt_mc[(dp_mc >= dp) & (sz_mc >= sz)]) for sz in sizes] for dp in dphis ], dtype=float)\n",
    "    b_mc_scan = np.array([ [np.sum(wt_mc[(dp_mc >= dp) & (sz_mc < sz)]) for sz in sizes] for dp in dphis ], dtype=float)\n",
    "    c_mc_scan = np.array([ [np.sum(wt_mc[(dp_mc < dp) & (sz_mc < sz)]) for sz in sizes] for dp in dphis ], dtype=float)\n",
    "    d_mc_scan = np.array([ [np.sum(wt_mc[(dp_mc < dp) & (sz_mc >= sz)]) for sz in sizes] for dp in dphis ], dtype=float)\n",
    "\n",
    "    a_r3_scan = np.array([ [np.sum(wt_r3[(dp_r3 >= dp) & (sz_r3 >= sz)]) for sz in sizes] for dp in dphis ], dtype=float)\n",
    "    b_r3_scan = np.array([ [np.sum(wt_r3[(dp_r3 >= dp) & (sz_r3 < sz)]) for sz in sizes] for dp in dphis ], dtype=float)\n",
    "    c_r3_scan = np.array([ [np.sum(wt_r3[(dp_r3 < dp) & (sz_r3 < sz)]) for sz in sizes] for dp in dphis ], dtype=float)\n",
    "    d_r3_scan = np.array([ [np.sum(wt_r3[(dp_r3 < dp) & (sz_r3 >= sz)]) for sz in sizes] for dp in dphis ], dtype=float)\n",
    "\n",
    "# a_mc_scan = np.array([ [xx.GetValue() for xx in x] for x in a_mc_scan ])\n",
    "# b_mc_scan = np.array([ [xx.GetValue() for xx in x] for x in b_mc_scan ])\n",
    "# c_mc_scan = np.array([ [xx.GetValue() for xx in x] for x in c_mc_scan ])\n",
    "# d_mc_scan = np.array([ [xx.GetValue() for xx in x] for x in d_mc_scan ])\n",
    "\n",
    "# a_r3_scan = np.array([ [xx.GetValue() for xx in x] for x in a_r3_scan ])\n",
    "# b_r3_scan = np.array([ [xx.GetValue() for xx in x] for x in b_r3_scan ])\n",
    "# c_r3_scan = np.array([ [xx.GetValue() for xx in x] for x in c_r3_scan ])\n",
    "# d_r3_scan = np.array([ [xx.GetValue() for xx in x] for x in d_r3_scan ])\n",
    "\n",
    "ap_mc_scan = np.divide(b_mc_scan*d_mc_scan, c_mc_scan, where=c_mc_scan>0, out=np.zeros_like(a_mc_scan))\n",
    "ap_r3_scan = np.divide(b_r3_scan*d_r3_scan, c_r3_scan, where=c_r3_scan>0, out=np.zeros_like(a_r3_scan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# There has to be signal and data in each of the 4 bins for the ABCD method to work\n",
    "# ! COMBINE STRUGGLES WHEN \"Bin [bin] has no signal processes contributing to it\"\n",
    "cond = ((a_mc_scan>0) & (b_mc_scan>0) & (c_mc_scan>0) & (d_mc_scan>0)) & \\\n",
    "        ((ap_r3_scan>0) & (b_r3_scan>0) & (c_r3_scan>0) & (d_r3_scan>0))\n",
    "# cond = (a_mc_scan>0) & (b_r3_scan>0) & (c_r3_scan>0) & (d_r3_scan>0)\n",
    "\n",
    "# Here we add a condition that the predicted value must be within 1 sigma of the actual value\n",
    "ae_r3_scan = np.sqrt(a_r3_scan)\n",
    "ape_r3_scan = ap_r3_scan * np.sqrt(\n",
    "    np.divide(1,b_r3_scan, where=cond, out=np.zeros_like(b_r3_scan)) +#ones_like(b_r3_scan)) +\n",
    "    np.divide(1,c_r3_scan, where=cond, out=np.zeros_like(c_r3_scan)) +#ones_like(c_r3_scan)) +\n",
    "    np.divide(1,d_r3_scan, where=cond, out=np.zeros_like(d_r3_scan))#ones_like(d_r3_scan))\n",
    ")\n",
    "\n",
    "closure_cond = np.divide(np.abs(a_r3_scan-ap_r3_scan),np.sqrt(ae_r3_scan**2 + ape_r3_scan**2), where=cond, out=999*np.ones_like(a_r3_scan))<1 \n",
    "if (cond & closure_cond).any():\n",
    "    cond = cond & closure_cond\n",
    "else:\n",
    "    print(\"SKIPPING CLOSURE CONDITION\")\n",
    "# cond = cond & (np.divide(np.abs(a_r3_scan-ap_r3_scan),np.sqrt(ape_r3_scan**2), where=cond, out=999*np.ones_like(a_r3_scan))<1)\n",
    "# cond = cond & (a_mc>700)\n",
    "# cond = cond & (ap_r3_scan<1)\n",
    "\n",
    "####\n",
    "\n",
    "# # Z = S / sqrt[ B ]\n",
    "s2bs = np.divide(a_mc_scan, np.sqrt(ap_r3_scan), where=cond, out=np.zeros_like(a_mc_scan))\n",
    "limits = 3*np.sqrt(ap_r3_scan)/a_mc_scan*cond\n",
    "# s2bs = np.divide(a_mc_scan, ape_r3_scan, where=cond, out=np.zeros_like(a_mc_scan))\n",
    "# limits = 3*ape_r3_scan/a_mc_scan*cond\n",
    "\n",
    "# # Z = S / sqrt[ S + B ]\n",
    "# s2bs = np.divide(a_mc_scan, np.sqrt(a_mc_scan + ap_r3_scan), where=cond, out=np.zeros_like(a_mc_scan))\n",
    "# s2bs = np.divide(a_mc_scan, np.sqrt(a_mc_scan + ape_r3_scan**2), where=cond, out=np.zeros_like(a_mc_scan))\n",
    "# limit = ???\n",
    "\n",
    "# Z = 2 * (sqrt[ S + B ] - sqrt[ B ]), https://arxiv.org/pdf/hep-ph/0204326.pdf\n",
    "# s2bs = 2*(np.sqrt(a_mc_scan+ap_r3_scan)-np.sqrt(ap_r3_scan))*cond\n",
    "# limits = ((3/2 + np.sqrt(ap_r3_scan))**2 - ap_r3_scan)/a_mc_scan*cond\n",
    "# s2bs = 2*(np.sqrt(a_mc_scan+ape_r3_scan**2)-ape_r3_scan)*cond #! I have found that this produces the best results\n",
    "# limits = ((3/2 + ape_r3_scan)**2 - ape_r3_scan**2)/a_mc_scan*cond\n",
    "\n",
    "# a_s2bs = 2*np.sqrt(a_mc_scan+ap_r3_scan)-np.sqrt(ap_r3_scan)\n",
    "# b_s2bs = 2*np.sqrt(b_mc_scan+b_r3_scan)-np.sqrt(b_r3_scan)\n",
    "# c_s2bs = 2*np.sqrt(c_mc_scan+c_r3_scan)-np.sqrt(c_r3_scan)\n",
    "# d_s2bs = 2*np.sqrt(d_mc_scan+d_r3_scan)-np.sqrt(d_r3_scan)\n",
    "# s2bs = np.sqrt(\n",
    "#     a_s2bs**2+\n",
    "#     b_s2bs**2+\n",
    "#     c_s2bs**2+\n",
    "#     d_s2bs**2\n",
    "# )*cond\n",
    "# print(np.max(s2bs), (s2bs==np.max(s2bs)).sum())\n",
    "# adj to limit from run2\n",
    "# s2bs = 2*(np.sqrt(2.16e-03*a_mc_scan+ap_r3_scan)-np.sqrt(ap_r3_scan))*cond\n",
    "\n",
    "# s2bs = ((3/2+np.sqrt(ap_r3_scan))**2-ap_r3_scan)/a_mc_scan * cond # limit\n",
    "# s2bs = ((1.96/2+ape_r3_scan)**2-ap_r3_scan)/a_mc_scan * cond # limit\n",
    "# s2bs = ((3/2+ape_r3_scan)**2-ap_r3_scan)/a_mc_scan * cond # limit\n",
    "# s2bs = ((3/2+ape_r3_scan)**2-ape_r3_scan)/a_mc_scan * cond # limit\n",
    "\n",
    "s2bs[:3,:] = 0\n",
    "s2bs[-4:,:] = 0\n",
    "s2bs[:,:3] = 0\n",
    "s2bs[:,-4:] = 0\n",
    "\n",
    "limits[(limits == 0) | np.isnan(limits)] = np.max(limits)\n",
    "limits[:3,:] = np.max(limits)\n",
    "limits[-4:,:] = np.max(limits)\n",
    "limits[:,:3] = np.max(limits)\n",
    "limits[:,-4:] = np.max(limits)\n",
    "\n",
    "idx = np.unravel_index(np.argmax(s2bs), s2bs.shape)\n",
    "# idx = np.unravel_index(np.argmin(limits), limits.shape)\n",
    "\n",
    "print(f's2b   = {s2bs[idx]:.1f}')\n",
    "print(f'limit = {limits[idx]:.2e}')\n",
    "print(f'dphi  = {dphis[idx[0]]:.2f}')\n",
    "print(f'size  = {sizes[idx[1]]:.0f}')\n",
    "print(f'a_mc  = {a_mc_scan[idx]:.1f}')\n",
    "if 'OOT' not in FN_R3:\n",
    "    print(f'a_r3 = --')\n",
    "else:\n",
    "    print(f'a_r3 = {a_r3_scan[idx]:.0f}')\n",
    "print(f'ap_r3 = {ap_r3_scan[idx]:.1f} +/- {ape_r3_scan[idx]:.2f}')\n",
    "\n",
    "ABCD_DPHI = dphis[idx[0]]\n",
    "ABCD_SIZE = sizes[idx[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, b, be = a_mc_scan[idx], ap_r3_scan[idx], ape_r3_scan[idx]\n",
    "\n",
    "#\n",
    "s1 = s / (b**0.5)\n",
    "s1_lmt = 3*(b**0.5)/s\n",
    "\n",
    "s12 = 2*((s + b)**0.5 - b**0.5)\n",
    "s12_lmt = ((3/2 + b**0.5)**2 - b)/s\n",
    "\n",
    "#\n",
    "s1e = s / be\n",
    "s1e_lmt = 3*be/s\n",
    "\n",
    "s12e = 2*((s + be**2)**0.5 - be)\n",
    "s12e_lmt = ((3/2 + be)**2 - be**2)/s\n",
    "\n",
    "#\n",
    "print(f'S1    = {s1:.1f} ({s1_lmt:.2e})')\n",
    "print(f'S1e   = {s1e:.1f} ({s1e_lmt:.2e})')\n",
    "print('')\n",
    "print(f'2S12  = {s12:.1f} ({s12_lmt:.2e})')\n",
    "print(f'2S12e = {s12e:.1f} ({s12e_lmt:.2e})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(idx, len(dphis),len(sizes))\n",
    "# plt.imshow(a_mc_scan.T[::-1,:], aspect='auto')\n",
    "# plt.imshow(np.log(a_mc_scan.T[::-1,:]), aspect='auto')\n",
    "# plt.imshow(ape_r3_scan.T[::-1,:], aspect='auto')\n",
    "# plt.imshow(np.log(ape_r3_scan.T[::-1,:]), aspect='auto')\n",
    "# plt.imshow(s2bs.T[::-1,:], aspect='auto')\n",
    "plt.imshow(np.log(s2bs.T[::-1,:]), aspect='auto')\n",
    "# plt.imshow(limits.T[::-1,:], aspect='auto')\n",
    "# plt.imshow(np.log(limits.T[::-1,:]), aspect='auto')\n",
    "plt.scatter([idx[0]], [len(sizes)-idx[1]], c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = TCanvas('','',2*800,800)\n",
    "canvas.Divide(2,1)\n",
    "\n",
    "dopt = ('col','box')[0]\n",
    "nb = 25\n",
    "\n",
    "form = ('',f';#Delta#phi_{{CSC,{SIZE_VAR.upper()}}};{SIZE_VAR.upper()} Size;count',nb,0,np.pi,nb,50,150)\n",
    "\n",
    "dphi_line = TLine(ABCD_DPHI,50,ABCD_DPHI,150)\n",
    "size_line = TLine(0,ABCD_SIZE,np.pi,ABCD_SIZE)\n",
    "dphi_line.SetLineWidth(3)\n",
    "size_line.SetLineWidth(3)\n",
    "\n",
    "if 'high' in FN_R3:\n",
    "    sr_box = TBox(0, ABCD_SIZE, ABCD_DPHI, 150)\n",
    "else:# 'low' in FN_R3:\n",
    "    sr_box = TBox(ABCD_DPHI, ABCD_SIZE, np.pi, 150)\n",
    "sr_box.SetFillColor(rt.kBlack)\n",
    "\n",
    "latex = TLatex()\n",
    "latex.SetTextAlign(23)\n",
    "latex.SetTextSize(0.04)\n",
    "\n",
    "canvas.cd(1).SetGrid()\n",
    "h_mc = rdfs['mc'].Histo2D(form,'tag_dPhi','tag_size').GetValue()\n",
    "h_mc.Draw(dopt)\n",
    "\n",
    "dphi_line.Draw()\n",
    "size_line.Draw()\n",
    "latex.DrawLatexNDC(0.5, 1, 'Signal'+(f', {SIZE_VAR.upper()}_{{OOT}}' if 'OOT' in FN_MC else ''))\n",
    "\n",
    "canvas.cd(2).SetGrid()\n",
    "h_r3 = rdfs['r3'].Histo2D(form,'tag_dPhi','tag_size').GetValue()\n",
    "h_r3.Draw(dopt)\n",
    "\n",
    "dphi_line.Draw()\n",
    "size_line.Draw()\n",
    "latex.DrawLatexNDC(0.5, 1, 'Data'+(f', {SIZE_VAR.upper()}_{{OOT}}' if 'OOT' in FN_R3 else ''))\n",
    "if 'OOT' not in FN_R3:\n",
    "    sr_box.Draw()\n",
    "\n",
    "canvas.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Size Closure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = TCanvas('','',800,800)\n",
    "canvas.SetGrid()\n",
    "canvas.SetLogy()\n",
    "\n",
    "legend = TLegend(0.38, 0.78, 0.68, 0.94)\n",
    "legend.SetBorderSize(0)\n",
    "legend.SetFillColorAlpha(rt.kBlack, 0)#0.2)\n",
    "legend.SetTextSize(0.04)\n",
    "legend.SetMargin(0.1)\n",
    "\n",
    "# sizes = np.linspace(50,150,100)\n",
    "\n",
    "if 'high' in FN_MC:\n",
    "    a_mc = [rdfs['mc'].Filter(f'(tag_dPhi < {ABCD_DPHI}) && (tag_size >= {sz})').Sum('weight') for sz in sizes]\n",
    "    b_mc = [rdfs['mc'].Filter(f'(tag_dPhi < {ABCD_DPHI}) && (tag_size < {sz})').Sum('weight') for sz in sizes]\n",
    "    c_mc = [rdfs['mc'].Filter(f'(tag_dPhi >= {ABCD_DPHI}) && (tag_size < {sz})').Sum('weight') for sz in sizes]\n",
    "    d_mc = [rdfs['mc'].Filter(f'(tag_dPhi >= {ABCD_DPHI}) && (tag_size >= {sz})').Sum('weight') for sz in sizes]\n",
    "\n",
    "    a_r3 = [rdfs['r3'].Filter(f'(tag_dPhi < {ABCD_DPHI}) && (tag_size >= {sz})').Sum('weight') for sz in sizes]\n",
    "    b_r3 = [rdfs['r3'].Filter(f'(tag_dPhi < {ABCD_DPHI}) && (tag_size < {sz})').Sum('weight') for sz in sizes]\n",
    "    c_r3 = [rdfs['r3'].Filter(f'(tag_dPhi >= {ABCD_DPHI}) && (tag_size < {sz})').Sum('weight') for sz in sizes]\n",
    "    d_r3 = [rdfs['r3'].Filter(f'(tag_dPhi >= {ABCD_DPHI}) && (tag_size >= {sz})').Sum('weight') for sz in sizes]\n",
    "else:\n",
    "    a_mc = [rdfs['mc'].Filter(f'(tag_dPhi >= {ABCD_DPHI}) && (tag_size >= {sz})').Sum('weight') for sz in sizes]\n",
    "    b_mc = [rdfs['mc'].Filter(f'(tag_dPhi >= {ABCD_DPHI}) && (tag_size < {sz})').Sum('weight') for sz in sizes]\n",
    "    c_mc = [rdfs['mc'].Filter(f'(tag_dPhi < {ABCD_DPHI}) && (tag_size < {sz})').Sum('weight') for sz in sizes]\n",
    "    d_mc = [rdfs['mc'].Filter(f'(tag_dPhi < {ABCD_DPHI}) && (tag_size >= {sz})').Sum('weight') for sz in sizes]\n",
    "\n",
    "    a_r3 = [rdfs['r3'].Filter(f'(tag_dPhi >= {ABCD_DPHI}) && (tag_size >= {sz})').Sum('weight') for sz in sizes]\n",
    "    b_r3 = [rdfs['r3'].Filter(f'(tag_dPhi >= {ABCD_DPHI}) && (tag_size < {sz})').Sum('weight') for sz in sizes]\n",
    "    c_r3 = [rdfs['r3'].Filter(f'(tag_dPhi < {ABCD_DPHI}) && (tag_size < {sz})').Sum('weight') for sz in sizes]\n",
    "    d_r3 = [rdfs['r3'].Filter(f'(tag_dPhi < {ABCD_DPHI}) && (tag_size >= {sz})').Sum('weight') for sz in sizes]\n",
    "\n",
    "a_mc = np.array([x.GetValue() for x in a_mc])\n",
    "b_mc = np.array([x.GetValue() for x in b_mc])\n",
    "c_mc = np.array([x.GetValue() for x in c_mc])\n",
    "d_mc = np.array([x.GetValue() for x in d_mc])\n",
    "\n",
    "a_r3 = np.array([x.GetValue() for x in a_r3])\n",
    "b_r3 = np.array([x.GetValue() for x in b_r3])\n",
    "c_r3 = np.array([x.GetValue() for x in c_r3])\n",
    "d_r3 = np.array([x.GetValue() for x in d_r3])\n",
    "\n",
    "ap_mc = np.array([b*d/c if c else -1 for b,c,d in zip(b_mc,c_mc,d_mc)])\n",
    "ap_r3 = np.array([b*d/c if c else -1 for b,c,d in zip(b_r3,c_r3,d_r3)])\n",
    "\n",
    "ae_mc = np.sqrt(a_mc)\n",
    "ae_r3 = np.sqrt(a_r3)\n",
    "ape_mc = np.array([a*(1/b+1/c+1/d)**(1/2) if b and c and d else 0 for a,b,c,d in zip(ap_mc,b_mc,c_mc,d_mc)])\n",
    "ape_r3 = np.array([a*(1/b+1/c+1/d)**(1/2) if b and c and d else 0 for a,b,c,d in zip(ap_r3,b_r3,c_r3,d_r3)])\n",
    "\n",
    "# **** #\n",
    "xx = sizes\n",
    "xlabel, ylabel = f'{SIZE_VAR.upper()} Size ABCD Boundary', 'Events in SR'\n",
    "\n",
    "values = [[a_r3,ae_r3],[ap_r3,ape_r3]]#,[a_mc,ae_mc],[ap_mc,ape_mc]]\n",
    "names = ['Data', 'Data Prediction']#,'Signal', 'Signal Prediction',]\n",
    "\n",
    "hmin, hmax = 0, 1.1*max([max(v[0]) for v in values])\n",
    "# hmin, hmax = 1e-9, 1.1*max([max(v[0]) for v in values])\n",
    "for igr, (vv, ve) in enumerate(values):\n",
    "    # if 'median' in ylabel.lower():\n",
    "    #     yy = np.array([[np.median(v),np.median(v)-np.percentile(v,25),np.percentile(v,75)-np.median(v)] if len(v) else [0,0,0] for v in val])\n",
    "    # elif 'mean' in ylabel.lower():\n",
    "    #     yy = np.array([[v.mean(),v.mean()-np.percentile(v,25),np.percentile(v,75)-v.mean()] if len(v) else [0,0,0] for v in val])\n",
    "    gr = TGraphErrors(len(xx),xx*1.,vv*1.,xx*0.,ve*1.)\n",
    "    gr.GetXaxis().SetLimits(np.min(xx), np.max(xx))\n",
    "    gr.SetMinimum(hmin)\n",
    "    gr.SetMaximum(hmax)\n",
    "    gr.SetName(names[igr])\n",
    "    gr.GetXaxis().SetTitle(xlabel)\n",
    "    gr.GetYaxis().SetTitle(ylabel)\n",
    "\n",
    "    gr.SetLineWidth(3)\n",
    "    gr.SetLineColor(SCL[igr])\n",
    "    # gr.SetLineColor(SCL[0 if 'Signal' in names[igr] else 1])\n",
    "    gr.SetLineStyle(rt.kDashed if '<' in names[igr] else rt.kSolid)\n",
    "    gr.SetFillColorAlpha(gr.GetLineColor(), 0.3)\n",
    "    gr.Draw(('' if igr else 'A')+' L3')\n",
    "    legend.AddEntry(gr,gr.GetName(),'LP')\n",
    "    gc.append(gr)\n",
    "\n",
    "size_line = TLine(ABCD_SIZE,0,ABCD_SIZE,hmax)\n",
    "size_line.Draw()\n",
    "size_line.SetLineWidth(3)\n",
    "\n",
    "legend.Draw()\n",
    "canvas.Draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table\n",
    "idx0 = np.argwhere(sizes == ABCD_SIZE)[0][0]\n",
    "print(r'\\begin{center}')\n",
    "print(r'\\begin{tabular}{c|cccc|c}')\n",
    "print(r'    \\hline')\n",
    "print(f'    \\\\textbf{{{SIZE_VAR.upper()} Size}} & D & C & B & A & $A_{{pred}}=\\\\frac{{B \\\\cdot D}}{{C}}$ \\\\\\\\')\n",
    "print(r'    \\hline\\hline')\n",
    "for i in range(idx0-3, idx0+4):\n",
    "    print(f'    {sizes[i]:.0f} & {d_r3[i]:.0f} & {c_r3[i]:.0f} & {b_r3[i]:.0f} & {a_r3[i]:.0f} ($\\pm$ {a_r3[i]**0.5:.2f}) & {ap_r3[i]:.2f} ($\\pm$ {ape_r3[i]:.2f}) \\\\\\\\')\n",
    "    if i-idx0 in (-1, 0):\n",
    "        print(r'    \\hline')\n",
    "print(r'\\end{tabular}')\n",
    "print(r'\\end{center}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deltaPhi Closure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = TCanvas('','',800,800)\n",
    "canvas.SetGrid()\n",
    "# canvas.SetLogy()\n",
    "\n",
    "legend = TLegend(0.38, 0.78, 0.68, 0.94)\n",
    "legend.SetBorderSize(0)\n",
    "legend.SetFillColorAlpha(rt.kBlack, 0)#0.2)\n",
    "legend.SetTextSize(0.04)\n",
    "legend.SetMargin(0.1)\n",
    "\n",
    "# dphis = np.linspace(0.4,np.pi,100)\n",
    "\n",
    "if 'high' in FN_MC:\n",
    "    a_mc = [rdfs['mc'].Filter(f'(tag_dPhi < {dp}) && (tag_size >= {ABCD_SIZE})').Sum('weight') for dp in dphis]\n",
    "    b_mc = [rdfs['mc'].Filter(f'(tag_dPhi < {dp}) && (tag_size < {ABCD_SIZE})').Sum('weight') for dp in dphis]\n",
    "    c_mc = [rdfs['mc'].Filter(f'(tag_dPhi >= {dp}) && (tag_size < {ABCD_SIZE})').Sum('weight') for dp in dphis]\n",
    "    d_mc = [rdfs['mc'].Filter(f'(tag_dPhi >= {dp}) && (tag_size >= {ABCD_SIZE})').Sum('weight') for dp in dphis]\n",
    "\n",
    "    a_r3 = [rdfs['r3'].Filter(f'(tag_dPhi < {dp}) && (tag_size >= {ABCD_SIZE})').Sum('weight') for dp in dphis]\n",
    "    b_r3 = [rdfs['r3'].Filter(f'(tag_dPhi < {dp}) && (tag_size < {ABCD_SIZE})').Sum('weight') for dp in dphis]\n",
    "    c_r3 = [rdfs['r3'].Filter(f'(tag_dPhi >= {dp}) && (tag_size < {ABCD_SIZE})').Sum('weight') for dp in dphis]\n",
    "    d_r3 = [rdfs['r3'].Filter(f'(tag_dPhi >= {dp}) && (tag_size >= {ABCD_SIZE})').Sum('weight') for dp in dphis]\n",
    "else:\n",
    "    a_mc = [rdfs['mc'].Filter(f'(tag_dPhi >= {dp}) && (tag_size >= {ABCD_SIZE})').Sum('weight') for dp in dphis]\n",
    "    b_mc = [rdfs['mc'].Filter(f'(tag_dPhi >= {dp}) && (tag_size < {ABCD_SIZE})').Sum('weight') for dp in dphis]\n",
    "    c_mc = [rdfs['mc'].Filter(f'(tag_dPhi < {dp}) && (tag_size < {ABCD_SIZE})').Sum('weight') for dp in dphis]\n",
    "    d_mc = [rdfs['mc'].Filter(f'(tag_dPhi < {dp}) && (tag_size >= {ABCD_SIZE})').Sum('weight') for dp in dphis]\n",
    "\n",
    "    a_r3 = [rdfs['r3'].Filter(f'(tag_dPhi >= {dp}) && (tag_size >= {ABCD_SIZE})').Sum('weight') for dp in dphis]\n",
    "    b_r3 = [rdfs['r3'].Filter(f'(tag_dPhi >= {dp}) && (tag_size < {ABCD_SIZE})').Sum('weight') for dp in dphis]\n",
    "    c_r3 = [rdfs['r3'].Filter(f'(tag_dPhi < {dp}) && (tag_size < {ABCD_SIZE})').Sum('weight') for dp in dphis]\n",
    "    d_r3 = [rdfs['r3'].Filter(f'(tag_dPhi < {dp}) && (tag_size >= {ABCD_SIZE})').Sum('weight') for dp in dphis]\n",
    "\n",
    "a_mc = np.array([x.GetValue() for x in a_mc])\n",
    "b_mc = np.array([x.GetValue() for x in b_mc])\n",
    "c_mc = np.array([x.GetValue() for x in c_mc])\n",
    "d_mc = np.array([x.GetValue() for x in d_mc])\n",
    "\n",
    "a_r3 = np.array([x.GetValue() for x in a_r3])\n",
    "b_r3 = np.array([x.GetValue() for x in b_r3])\n",
    "c_r3 = np.array([x.GetValue() for x in c_r3])\n",
    "d_r3 = np.array([x.GetValue() for x in d_r3])\n",
    "\n",
    "ap_mc = np.array([b*d/c if c else -1 for b,c,d in zip(b_mc,c_mc,d_mc)])\n",
    "ap_r3 = np.array([b*d/c if c else -1 for b,c,d in zip(b_r3,c_r3,d_r3)])\n",
    "\n",
    "ae_mc = np.sqrt(a_mc)\n",
    "ae_r3 = np.sqrt(a_r3)\n",
    "ape_mc = np.array([a*(1/b+1/c+1/d)**(1/2) if b and c and d else 0 for a,b,c,d in zip(ap_mc,b_mc,c_mc,d_mc)])\n",
    "ape_r3 = np.array([a*(1/b+1/c+1/d)**(1/2) if b and c and d else 0 for a,b,c,d in zip(ap_r3,b_r3,c_r3,d_r3)])\n",
    "\n",
    "# **** #\n",
    "xx = dphis\n",
    "xlabel, ylabel = f'|#Delta#phi_{{CSC,{SIZE_VAR.upper()}}}| ABCD Boundary', 'Events in SR'\n",
    "\n",
    "values = [[a_r3,ae_r3],[ap_r3,ape_r3]]#,[a_mc,ae_mc],[ap_mc,ape_mc]]\n",
    "names = ['Data', 'Data Prediction']#,'Signal', 'Signal Prediction',]\n",
    "\n",
    "hmin, hmax = 0, 1.1*max([max(v[0]) for v in values])\n",
    "for igr, (vv, ve) in enumerate(values):\n",
    "    # if 'median' in ylabel.lower():\n",
    "    #     yy = np.array([[np.median(v),np.median(v)-np.percentile(v,25),np.percentile(v,75)-np.median(v)] if len(v) else [0,0,0] for v in val])\n",
    "    # elif 'mean' in ylabel.lower():\n",
    "    #     yy = np.array([[v.mean(),v.mean()-np.percentile(v,25),np.percentile(v,75)-v.mean()] if len(v) else [0,0,0] for v in val])\n",
    "    gr = TGraphErrors(len(xx),xx*1.,vv*1.,xx*0.,ve*1.)\n",
    "    gr.GetXaxis().SetLimits(np.min(xx), np.max(xx))\n",
    "    gr.SetMinimum(hmin)\n",
    "    gr.SetMaximum(hmax)\n",
    "    gr.SetName(names[igr])\n",
    "    gr.GetXaxis().SetTitle(xlabel)\n",
    "    gr.GetYaxis().SetTitle(ylabel)\n",
    "\n",
    "    gr.SetLineWidth(3)\n",
    "    gr.SetLineColor(SCL[igr])\n",
    "    # gr.SetLineColor(SCL[0 if 'Signal' in names[igr] else 1])\n",
    "    gr.SetLineStyle(rt.kDashed if '<' in names[igr] else rt.kSolid)\n",
    "    gr.SetFillColorAlpha(gr.GetLineColor(), 0.3)\n",
    "    gr.Draw(('' if igr else 'A')+' L3')\n",
    "    legend.AddEntry(gr,gr.GetName(),'LP')\n",
    "    gc.append(gr)\n",
    "\n",
    "dphi_line = TLine(ABCD_DPHI,0,ABCD_DPHI,hmax)\n",
    "dphi_line.Draw()\n",
    "dphi_line.SetLineWidth(3)\n",
    "\n",
    "legend.Draw()\n",
    "canvas.Draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table\n",
    "idx0 = np.argwhere(dphis == ABCD_DPHI)[0][0]\n",
    "print(r'\\begin{center}')\n",
    "print(r'\\begin{tabular}{c|cccc|c}')\n",
    "print(r'    \\hline')\n",
    "print(f'    $\\\\mathbf{{|\\\\Delta\\\\phi_{{CSC,{SIZE_VAR.upper()}}}|}}$ & D & C & B & A & $A_{{pred}}=\\\\frac{{B \\\\cdot D}}{{C}}$ \\\\\\\\')\n",
    "print(r'    \\hline\\hline')\n",
    "for i in range(idx0-3, idx0+4):\n",
    "    print(f'    {dphis[i]:.2f} & {d_r3[i]:.0f} & {c_r3[i]:.0f} & {b_r3[i]:.0f} & {a_r3[i]:.0f} ($\\pm$ {a_r3[i]**0.5:.2f}) & {ap_r3[i]:.2f} ($\\pm$ {ape_r3[i]:.2f}) \\\\\\\\')\n",
    "    if i-idx0 in (-1, 0):\n",
    "        print(r'    \\hline')\n",
    "print(r'\\end{tabular}')\n",
    "print(r'\\end{center}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyroot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
